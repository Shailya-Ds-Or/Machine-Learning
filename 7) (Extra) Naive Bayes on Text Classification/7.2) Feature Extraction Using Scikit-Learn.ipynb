{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f7244e0",
   "metadata": {},
   "source": [
    "# Feature Extraction Using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72e4b09",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6af4808",
   "metadata": {},
   "source": [
    "## Bag of Words and Tf-idf\n",
    "In the above examples, each vector can be considered a *bag of words*. By itself these may not be helpful until we consider *term frequencies*, or how often individual words appear in documents. A simple way to calculate term frequencies is to divide the number of occurrences of a word by the total number of words in the document. In this way, the number of times a word appears in large documents can be compared to that of smaller documents.\n",
    "\n",
    "However, it may be hard to differentiate documents based on term frequency if a word shows up in a majority of documents. To handle this we also consider *inverse document frequency*, which is the total number of documents divided by the number of documents that contain the word. In practice we convert this value to a logarithmic scale, as described [here](https://en.wikipedia.org/wiki/Tf%E2%80%93idf#Inverse_document_frequency).\n",
    "\n",
    "Together these terms become [**tf-idf**](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29d19c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4e20bcf",
   "metadata": {},
   "source": [
    "## Stop Words and Word Stems\n",
    "\n",
    "Some words like \"the\" and \"and\" appear so frequently, and in so many documents, that we needn't bother counting them. Also, it may make sense to only record the root of a word, say `cat` in place of both `cat` and `cats`. This will shrink our vocab array and improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e76118c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7827d1b",
   "metadata": {},
   "source": [
    "## Tokenization and Tagging\n",
    "\n",
    "When we created our vectors the first thing we did was split the incoming text on whitespace with `.split()`. This was a crude form of *tokenization* - that is, dividing a document into individual words. In this simple example we didn't worry about punctuation or different parts of speech. In the real world we rely on some fairly sophisticated *morphology* to parse text appropriately.\n",
    "\n",
    "Once the text is divided, we can go back and *tag* our tokens with information about parts of speech, grammatical dependencies, etc. This adds more dimensions to our data and enables a deeper understanding of the context of specific documents. For this reason, vectors become ***high dimensional sparse matrices***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e55a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67fe7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"This is first line\", \"This is second Line\", \"Another LINE\", \"not the FIrst linE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb22717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048627f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd62c2eb",
   "metadata": {},
   "source": [
    "#### 1) Count Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d5a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135145ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 14 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "690a4b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_mat = cv.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "955111dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 14 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f6c92ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1, 1, 1, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 1, 0, 1, 0, 1],\n",
       "        [1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 1, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_mat.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc962d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43341fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words= \"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb177ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_mat= cv.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b16bd3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x2 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dd304dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_mat.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e2a7a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'line': 0, 'second': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050662a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "478a1c51",
   "metadata": {},
   "source": [
    "#### 2) Tfidf Transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4284d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa240dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cee8fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_mat = cv.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35cfa013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 14 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aa0f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mat = tfidf_transformer.fit_transform(sparse_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b96dd1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x8 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee99fde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.53931298, 0.53931298, 0.35696573, 0.        ,\n",
       "         0.        , 0.        , 0.53931298],\n",
       "        [0.        , 0.        , 0.4970962 , 0.32902288, 0.        ,\n",
       "         0.6305035 , 0.        , 0.4970962 ],\n",
       "        [0.88654763, 0.        , 0.        , 0.46263733, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.46345796, 0.        , 0.30675807, 0.58783765,\n",
       "         0.        , 0.58783765, 0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mat.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ac1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ae1c86f",
   "metadata": {},
   "source": [
    "#### 3) Tfidf Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8bc0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9df77f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_mat = tfidf_vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d7da676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x8 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26dda1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.53931298, 0.53931298, 0.35696573, 0.        ,\n",
       "         0.        , 0.        , 0.53931298],\n",
       "        [0.        , 0.        , 0.4970962 , 0.32902288, 0.        ,\n",
       "         0.6305035 , 0.        , 0.4970962 ],\n",
       "        [0.88654763, 0.        , 0.        , 0.46263733, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.46345796, 0.        , 0.30675807, 0.58783765,\n",
       "         0.        , 0.58783765, 0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_mat.todense()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
